<meta charset="utf-8" emacsmode="-*- markdown -*-">

<title>
  Yun-Chun Chen's CV
</title>

<table style="margin-bottom:50px;">
  <tr>
    <td>
      [Download PDF](https://yunchunchen.github.io/CV/Yun-Chun_Chen_CV.pdf)
    </td>
    <td align="right">
      Last updated: August 3, 2024
    </td>
  </tr>
</table>

<table>
  <tr>
    <td rowspan="2" style="font-size:300%; font-variant: small-caps;">
      [Yun-Chun Chen](https://yunchunchen.github.io/)
    </td>
    <td align="right">
      Email: [ycchen@cs.toronto.edu](mailto:ycchen@cs.toronto.edu)
    </td>
  </tr>
  <tr>
    <td align="right">
      Web: [yunchunchen.github.io](https://yunchunchen.github.io/)
    </td>
  </tr>
</table>

(#) Research Interests

<table>
  <tr>
    <td>
      Generative AI, &nbsp;
      Large Language Models, &nbsp;
      Vision Language Models, &nbsp;
      Multimodal AI, &nbsp;
      Geometric & 3D Deep Learning.
    </td>
  </tr>
</table>

(#) Education

<table>
  <tr>
    <td>
      <b>[University of Toronto, ON, Canada](https://www.utoronto.ca/)</b>
    </td>
    <td align="right">
      Sep 2020 - 2025 (expected)
    </td>
  </tr>
  <tr>
    <td>
      Ph.D. Candidate in [Computer Science](https://web.cs.toronto.edu/).
    </td>
  </tr>
  <tr>
    <td>
      Advisor: [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      Committee: 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/), 
      [Sanja Fidler](https://www.cs.utoronto.ca/~fidler/), 
      [Sven Dickinson](https://www.cs.toronto.edu/~sven/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[National Taiwan University, Taipei, Taiwan](https://www.ntu.edu.tw/english/)</b>
    </td>
    <td align="right">
      Sep 2014 - Jun 2018
    </td>
  </tr>
  <tr>
    <td>
      B.S. in [Electrical Engineering](https://web.ee.ntu.edu.tw/eng/index.php).
    </td>
  </tr>
</table>

(#) Work Experience

<table>
  <tr>
    <td>
      <b>[University of Toronto, ON, Canada](https://www.utoronto.ca/)</b>
    </td>
    <td align="right">
      Sep 2020 - Present
    </td>
  </tr>
  <tr>
    <td>
      Position: Graduate Research Assistant.
    </td>
  </tr>
  <tr>
    <td>
      Advisor: [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Working on generative AI and 3D deep learning research.</li></ul>
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on cloth upsampling.</li></ul>
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on 3D shape assembly.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Meta Reality Labs, Burlingame, CA, USA](https://about.meta.com/realitylabs/)</b>
    </td>
    <td align="right">
      May 2024 - Present
    </td>
  </tr>
  <tr>
    <td>
      Position: Research Scientist Intern.
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Working on 4D Gaussian Splatting for codec avatar applications.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Adobe Research, Seattle, WA, USA](https://research.adobe.com/)</b>
    </td>
    <td align="right">
      Jun 2023 - Sep 2023
    </td>
  </tr>
  <tr>
    <td>
      Position: Research Scientist Intern.
    </td>
  </tr>
  <tr>
    <td>
      Mentors: 
      [Matheus Gadelha](http://mgadelha.me/), 
      [Vova Kim](http://www.vovakim.com/), 
      [Zhiqin Chen](https://czq142857.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on controllable text-to-3D generation.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Adobe Research, Toronto, ON, Canada](https://research.adobe.com/)</b>
    </td>
    <td align="right">
      Jun 2022 - Jan 2023
    </td>
  </tr>
  <tr>
    <td>
      Position: Research Scientist Intern.
    </td>
  </tr>
  <tr>
    <td>
      Mentors: 
      [Vova Kim](http://www.vovakim.com/), 
      [Noam Aigerman](https://noamaig.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on progressive representations for mesh compression and transmission.</li></ul>
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Filed a patent.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[NVIDIA Seattle Robotics Lab, WA, USA](https://nvidia_srl.gitlab.io/)</b>
    </td>
    <td align="right">
      May 2021 - Feb 2022
    </td>
  </tr>
  <tr>
    <td>
      Position: Research Intern (remote).
    </td>
  </tr>
  <tr>
    <td>
      Mentors: 
      [Adithya Murali](http://adithyamurali.com/), 
      [Balakumar Sundaralingam](https://balakumar-s.github.io/), 
      [Dieter Fox](https://homes.cs.washington.edu/~fox/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on implicit neural representations for robotic grasping and motion planning.</li></ul>
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Filed a patent.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[University of California, Merced, CA, USA](https://www.ucmerced.edu/)</b>
    </td>
    <td align="right">
      Jan 2020 - Jun 2020
    </td>
  </tr>
  <tr>
    <td>
      Position: Short-term Visiting Scholar.
    </td>
  </tr>
  <tr>
    <td>
      Mentor: [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on 3D human pose and shape estimation from videos.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Virginia Tech, VA, USA](https://www.vt.edu/)</b>
    </td>
    <td align="right">
      Apr 2019 - Jul 2019
    </td>
  </tr>
  <tr>
    <td>
      Position: Short-term Visiting Scholar.
    </td>
  </tr>
  <tr>
    <td>
      Mentor: [Jia-Bin Huang](https://jbhuang0604.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on neural architecture search for image restoration and synthesis.</li></ul>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Academia Sinica, Taipei, Taiwan](https://www.sinica.edu.tw/en)</b>
    </td>
    <td align="right">
      Jul 2017 - Jan 2019
    </td>
  </tr>
  <tr>
    <td>
      Position: Research Assistant.
    </td>
  </tr>
  <tr>
    <td>
      Mentors: 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/), 
      [Jia-Bin Huang](https://jbhuang0604.github.io/), 
      [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/).
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on unsupervised domain adaptation for dense prediction tasks.</li></ul>
    </td>
  </tr>
  <tr>
    <td>
      <ul><li>Worked on weakly supervised semantic matching and object co-segmentation.</li></ul>
    </td>
  </tr>
</table>

(#) Selected Publications

<table>
  <tr>
    <td>
      Google Scholar Profile: [scholar.google.com/citations?user=TiCSofEAAAAJ&hl=en](https://scholar.google.com/citations?user=TiCSofEAAAAJ&hl=en)
    </td>
  </tr>
</table>

(##) Conference and Journal Papers

<table>
  <tr>
    <td>
      <b>A paper on controllable text-to-3D generation.</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Selena Ling](https://iszihan.github.io/), 
      [Zhiqin Chen](https://czq142857.github.io/), 
      [Vladimir G. Kim](http://www.vovakim.com/), 
      [Matheus Gadelha](http://mgadelha.me/), 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      <i>Conditionally accepted.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>A paper on neural cloth upsampling.</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      others.
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Neural Progressive Meshes.](https://arxiv.org/abs/2308.05741)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Vladimir G. Kim](http://www.vovakim.com/), 
      [Noam Aigerman](https://noamaig.github.io/), 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      <i>ACM SIGGRAPH, 2023.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Breaking Bad: A Dataset for Geometric Fracture and Reassembly.](https://arxiv.org/abs/2210.11463)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Silvia Sell√°n](https://www.silviasellan.com/)<sup>&starf;</sup>, 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Ziyi Wu](https://wuziyi616.github.io/)<sup>&starf;</sup>, 
      Animesh Garg, 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      <i>Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2022.</i>
    </td>
  </tr>
  <tr>
    <td>
      <font color='red'>Featured Paper Presentation</font>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Grasp'D: Differentiable Contact-rich Grasp Synthesis for Multi-fingered Hands.](https://arxiv.org/abs/2208.12250)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Dylan Turpin](http://www.cs.toronto.edu/~dylanturpin/), 
      Liquan Wang, 
      [Eric Heiden](https://eric-heiden.com/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Miles Macklin](http://blog.mmacklin.com/about/), 
      [Stavros Tsogkas](http://tsogkas.github.io/), 
      [Sven Dickinson](https://www.cs.toronto.edu/~sven/), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>European Conference on Computer Vision (ECCV), 2022.</i>
    </td>
  </tr>
  <tr>
    <td>
      <font color='red'>Oral Presentation</font>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors.](https://arxiv.org/abs/2205.14886)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Haoda Li](https://lihd1003.github.io/), 
      [Dylan Turpin](http://www.cs.toronto.edu/~dylanturpin/), 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos.](https://arxiv.org/abs/2101.07241)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Haoyu Xiong](https://haoyu-x.github.io/), 
      [Quanzhou Li](https://quanzhou-li.github.io/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Homanga Bharadhwaj](https://homangab.github.io), 
      [Samarth Sinha](https://www.samsinha.me), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Show, Match and Segment: Joint Weakly Supervised Learning of Semantic Matching and Object Co-segmentation.](https://arxiv.org/abs/1906.05857)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/), 
      [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/), 
      [Jia-Bin Huang](https://jbhuang0604.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Self-Attentive 3D Human Pose and Shape Estimation from Videos.](https://arxiv.org/abs/2103.14182)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      Marco Piccirilli, 
      [Robinson Piramuthu](https://www.linkedin.com/in/rpiramuthu/), 
      [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/).
    </td>
  </tr>
  <tr>
    <td>
      <i>Computer Vision and Image Understanding (CVIU), 2021.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[NAS-DIP: Learning Deep Image Prior with Neural Architecture Search.](https://arxiv.org/abs/2008.11713)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Chen Gao](https://gaochen315.github.io)<sup>&starf;</sup>, 
      Esther Robb, 
      [Jia-Bin Huang](https://jbhuang0604.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <i>European Conference on Computer Vision (ECCV), 2020.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Learning to Learn in a Semi-Supervised Fashion.](https://arxiv.org/abs/2008.11203)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      Chao-Te Chou, 
      Yu-Chiang Frank Wang.
    </td>
  </tr>
  <tr>
    <td>
      <i>European Conference on Computer Vision (ECCV), 2020.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Recover and Identify: A Generative Dual Model for Cross-Resolution Person Re-Identification.](https://arxiv.org/abs/1908.06052)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Yu-Jhe Li](https://yujheli.github.io)<sup>&starf;</sup>, 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/), 
      Xiaofei Du, 
      Yu-Chiang Frank Wang.
    </td>
  </tr>
  <tr>
    <td>
      <i>IEEE International Conference on Computer Vision (ICCV), 2019.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[CrDoCo: Pixel-level Domain Transfer with Cross-Domain Consistency.](https://arxiv.org/abs/2001.03182)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/), 
      [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/), 
      [Jia-Bin Huang](https://jbhuang0604.github.io/).
    </td>
  </tr>
  <tr>
    <td>
      <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Learning Resolution-Invariant Deep Representations for Person Re-Identification.](https://arxiv.org/abs/1907.10843)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Yu-Jhe Li](https://yujheli.github.io)<sup>&starf;</sup>, 
      Xiaofei Du, 
      Yu-Chiang Frank Wang.
    </td>
  </tr>
  <tr>
    <td>
      <i>AAAI Conference on Artificial Intelligence (AAAI), 2019.</i>
    </td>
  </tr>
  <tr>
    <td>
      <font color='red'>Oral Presentation</font>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Deep Semantic Matching with Foreground Detection and Cycle-Consistency.](https://arxiv.org/abs/2004.00144)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      Po-Hsiang Huang, 
      Li-Yu Yu, 
      [Jia-Bin Huang](https://jbhuang0604.github.io/), 
      [Ming-Hsuan Yang](http://faculty.ucmerced.edu/mhyang/), 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/).
    </td>
  </tr>
  <tr>
    <td>
      <i>Asian Conference on Computer Vision (ACCV), 2018.</i>
    </td>
  </tr>
</table>

(##) Workshop Papers

<table>
  <tr>
    <td>
      <b>[Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value Functions.](https://arxiv.org/abs/2206.14854)</b>
    </td>
  </tr>
  <tr>
    <td>
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Adithyavairavan Murali](http://adithyamurali.com/)<sup>&starf;</sup>, 
      [Balakumar Sundaralingam](https://balakumar-s.github.io/)<sup>&starf;</sup>, 
      [Wei Yang](http://wyang.me/), 
      Animesh Garg, 
      [Dieter Fox](https://homes.cs.washington.edu/~fox/).
    </td>
  </tr>
  <tr>
    <td>
      <i>RSS 2022 Workshop on Implicit Representations for Robotic Manipulation, 2022.</i>
    </td>
  </tr>
  <tr>
    <td>
      <font color='red'>Spotlight Talk</font>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos.](https://arxiv.org/abs/2101.07241)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Haoyu Xiong](https://haoyu-x.github.io/), 
      [Quanzhou Li](https://quanzhou-li.github.io/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Homanga Bharadhwaj](https://homangab.github.io), 
      [Samarth Sinha](https://www.samsinha.me), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>RSS 2021 Workshop on Visual Learning and Reasoning for Robotics, 2021.</i>
    </td>
  </tr>
  <tr>
    <td>
      <font color='red'>Spotlight Talk</font>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos.](https://arxiv.org/abs/2101.07241)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Haoyu Xiong](https://haoyu-x.github.io/), 
      [Quanzhou Li](https://quanzhou-li.github.io/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Homanga Bharadhwaj](https://homangab.github.io), 
      [Samarth Sinha](https://www.samsinha.me), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>ICML 2021 Workshop on Human in the Loop Learning, 2021.</i>
    </td>
  </tr>
</table>

(##) Preprint

<table>
  <tr>
    <td>
      <b>[Cross-Resolution Adversarial Dual Network for Person Re-Identification and Beyond.](https://arxiv.org/abs/2002.09274)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Yu-Jhe Li](https://yujheli.github.io)<sup>&starf;</sup>, 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b><sup>&starf;</sup>, 
      [Yen-Yu Lin](https://sites.google.com/site/yylinweb/), 
      Yu-Chiang Frank Wang.
    </td>
  </tr>
  <tr>
    <td>
      <i>arXiv preprint arXiv:2002.09274</i>
    </td>
  </tr>
</table>

(#) Talks

<table>
  <tr>
    <td>
      <b>ACM SIGGRAPH 2023</b>
    </td>
    <td align="right">
      Aug 2023
    </td>
  </tr>
  <tr>
    <td>
      Neural Progressive Meshes.
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Toronto Geometry Colloquium](https://toronto-geometry-colloquium.github.io/)</b>
    </td>
    <td align="right">
      May 2022
    </td>
  </tr>
  <tr>
    <td>
      Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors.
    </td>
  </tr>
</table>

(#) Patents

<table>
  <tr>
    <td>
      <b>Progressively Generating Fine Polygon Meshes.</b>
    </td>
  </tr>
  <tr>
    <td>
      [Vladimir G. Kim](http://www.vovakim.com/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Noam Aigerman](https://noamaig.github.io/), 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
  <tr>
    <td>
      <i>Filed by Adobe.</i>
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      <b>[Techniques for Robot Control using Neural Implicit Value Functions.](https://patents.google.com/patent/US20230256595A1/en)</b>
    </td>
  </tr>
  <tr>
    <td>
      [Adithyavairavan Murali](http://adithyamurali.com/), 
      [Balakumar Sundaralingam](https://balakumar-s.github.io/), 
      <b>[Yun-Chun Chen](https://yunchunchen.github.io/)</b>, 
      [Dieter Fox](https://homes.cs.washington.edu/~fox/), 
      Animesh Garg.
    </td>
  </tr>
  <tr>
    <td>
      <i>US Patent Application No. 17/856,699</i>
    </td>
  </tr>
</table>
 
(#) Honors and Awards

<table>
  <tr>
    <td>
      Faculty of Arts and Science Program-level Fellowship, University of Toronto.
    </td>
    <td align="right">
      2023
    </td>
  </tr>
  <tr>
    <td>
      Ph.D. Conference Travel Grant for NeurIPS 2022.
    </td>
    <td align="right">
      2022
    </td>
  </tr>
  <tr>
    <td>
      Faculty of Arts and Science Program-level Fellowship, University of Toronto.
    </td>
    <td align="right">
      2022
    </td>
  </tr>
  <tr>
    <td>
      Vector Institute Research Grant.
    </td>
    <td align="right">
      2022
    </td>
  </tr>
  <tr>
    <td>
      University of Toronto Mississauga Travel Grant for CVPR 2022.
    </td>
    <td align="right">
      2022
    </td>
  </tr>
  <tr>
    <td>
      Faculty of Arts and Science Program-level Fellowship, University of Toronto.
    </td>
    <td align="right">
      2021
    </td>
  </tr>
  <tr>
    <td>
      Vector Institute Research Grant.
    </td>
    <td align="right">
      2021
    </td>
  </tr>
  <tr>
    <td>
      Top 25% of Program Committee Members of AAAI 2021.
    </td>
    <td align="right">
      2021
    </td>
  </tr>
  <tr>
    <td>
      Faculty of Arts and Science Program-level Fellowship, University of Toronto.
    </td>
    <td align="right">
      2020
    </td>
  </tr>
  <tr>
    <td>
      Appier AI Scholarship for ICCV 2019.
    </td>
    <td align="right">
      2019
    </td>
  </tr>
  <tr>
    <td>
      Appier AI Scholarship for CVPR 2019.
    </td>
    <td align="right">
      2019
    </td>
  </tr>
  <tr>
    <td>
      Appier AI Scholarship for AAAI 2019.
    </td>
    <td align="right">
      2019
    </td>
  </tr>
  <tr>
    <td>
      Third Place in IEEE Video and Image Processing (VIP) Cup.
    </td>
    <td align="right">
      2018
    </td>
  </tr>
</table>

(#) Teaching

(##) University of Toronto

<table>
  <tr>
    <td>
      CSC 420: Introduction to Image Understanding.
    </td>
    <td align="right">
      Winter 2024
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [Sanja Fidler](https://www.cs.utoronto.ca/~fidler/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 420: Introduction to Image Understanding.
    </td>
    <td align="right">
      Winter 2024
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [David Lindell](https://davidlindell.com/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 320: Introduction to Visual Computing.
    </td>
    <td align="right">
      Winter 2024
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [Kyros Kutulakos](https://www.cs.toronto.edu/~kyros/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 236: Introduction to the Theory of Computation.
    </td>
    <td align="right">
      Fall 2023
    </td>
  </tr>
  <tr>
    <td>
      Instructor: Francois Pitt.
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 420: Introduction to Image Understanding.
    </td>
    <td align="right">
      Winter 2023
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [Sanja Fidler](https://www.cs.utoronto.ca/~fidler/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 420: Introduction to Image Understanding.
    </td>
    <td align="right">
      Winter 2023
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [David Lindell](https://davidlindell.com/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 413/2516: Neural Networks and Deep Learning.
    </td>
    <td align="right">
      Winter 2023
    </td>
  </tr>
  <tr>
    <td>
      Instructors: 
      [Jimmy Ba](https://jimmylba.github.io/) 
      and 
      [Bo Wang](https://wanglab.ai/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 317: Computer Graphics.
    </td>
    <td align="right">
      Fall 2022
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [Karan Singh](https://www.dgp.toronto.edu/~karan/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 2521: Topics in Computer Graphics.
    </td>
    <td align="right">
      Fall 2022
    </td>
  </tr>
  <tr>
    <td>
      Instructor: 
      [Alec Jacobson](https://www.cs.toronto.edu/~jacobson/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 375: Algorithmic Intelligence in Robotics.
    </td>
    <td align="right">
      Winter 2022
    </td>
  </tr>
  <tr>
    <td>
      Instructor: Animesh Garg.
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 413/2516: Neural Networks and Deep Learning.
    </td>
    <td align="right">
      Winter 2022
    </td>
  </tr>
  <tr>
    <td>
      Instructors: 
      [Jimmy Ba](https://jimmylba.github.io/) 
      and 
      [Bo Wang](https://wanglab.ai/).
    </td>
  </tr>
</table>

<table>
  <tr>
    <td>
      CSC 413/2516: Neural Networks and Deep Learning.
    </td>
    <td align="right">
      Winter 2021
    </td>
  </tr>
  <tr>
    <td>
      Instructors: 
      [Jimmy Ba](https://jimmylba.github.io/) 
      and 
      [Bo Wang](https://wanglab.ai/).
    </td>
  </tr>
</table>

(##) National Taiwan University

<table>
  <tr>
    <td>
      EE 5184: Machine Learning.
    </td>
    <td align="right">
      Spring 2018
    </td>
  </tr>
  <tr>
    <td>
      EE 1004: Computer Programming.
    </td>
    <td align="right">
      Fall 2017
    </td>
  </tr>  
</table>

(#) Academic Service

(##) Senior Program Committee

<table>
  <tr>
    <td>
      International Joint Conference on Artificial Intelligence (IJCAI)
    </td>
    <td align="right">
      2021
    </td>
  </tr>  
</table>

(##) Program Committee / Conference Reviewer

<table>
  <tr>
    <td>
      Neural Information Processing Systems (NeurIPS)
    </td>
    <td align="right">
      2020, 2021, 2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      NeurIPS Datasets and Benchmarks Track
    </td>
    <td align="right">
      2022, 2023, 2024
    </td>
  </tr>
  <tr>
    <td>
      International Conference on Learning Representations (ICLR)
    </td>
    <td align="right">
      2021, 2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      International Conference on Machine Learning (ICML)
    </td>
    <td align="right">
      2021, 2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
    </td>
    <td align="right">
      2020, 2021, 2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      IEEE International Conference on Computer Vision (ICCV)
    </td>
    <td align="right">
      2019, 2021, 2023
    </td>
  </tr>  
  <tr>
    <td>
      European Conference on Computer Vision (ECCV)
    </td>
    <td align="right">
      2020, 2022, 2024
    </td>
  </tr>  
  <tr>
    <td>
      International Conference on 3D Vision (3DV)
    </td>
    <td align="right">
      2022
    </td>
  </tr>  
  <tr>
    <td>
      British Machine Vision Conference (BMVC)
    </td>
    <td align="right">
      2019, 2020, 2021, 2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      Asian Conference on Computer Vision (ACCV)
    </td>
    <td align="right">
      2020, 2022, 2024
    </td>
  </tr>  
  <tr>
    <td>
      IEEE Winter Conference on Applications of Computer Vision (WACV)
    </td>
    <td align="right">
      2021, 2022, 2023, 2024, 2025
    </td>
  </tr>  
  <tr>
    <td>
      ACM SIGGRAPH
    </td>
    <td align="right">
      2024
    </td>
  </tr>  
  <tr>
    <td>
      ACM SIGGRAPH Asia
    </td>
    <td align="right">
      2022, 2024
    </td>
  </tr>  
  <tr>
    <td>
      IEEE International Conference on Robotics and Automation (ICRA)
    </td>
    <td align="right">
      2021
    </td>
  </tr>  
  <tr>
    <td>
      Conference on Robot Learning (CoRL)
    </td>
    <td align="right">
      2020
    </td>
  </tr> 
  <tr>
    <td>
      International Symposium on Robotics Research (ISRR)
    </td>
    <td align="right">
      2022
    </td>
  </tr>  
  <tr>
    <td>
      International Joint Conference on Artificial Intelligence (IJCAI)
    </td>
    <td align="right">
      2022, 2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      AAAI Conference on Artificial Intelligence (AAAI)
    </td>
    <td align="right">
      2020, 2021, 2022, 2023, 2024, 2025
    </td>
  </tr>  
  <tr>
    <td>
      Conference on Lifelong Learning Agents (CoLLAs)
    </td>
    <td align="right">
      2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      Learning on Graphs Conference (LoG)
    </td>
    <td align="right">
      2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      International Conference on Artificial Intelligence and Statistics (AISTATS)
    </td>
    <td align="right">
      2023, 2024
    </td>
  </tr>  
  <tr>
    <td>
      IEEE International Conference on Image Processing (ICIP)
    </td>
    <td align="right">
      2019
    </td>
  </tr>  
  <tr>
    <td>
      Gordon Research Conference/Seminar in Robotics (GRS)
    </td>
    <td align="right">
      2022
    </td>
  </tr>  
</table>

(##) Journal Reviewer

<table>
  <tr>
    <td>
      International Journal of Computer Vision (IJCV)
    </td>
  </tr>  
  <tr>
    <td>
      Image and Vision Computing (IVC)
    </td>
  </tr>  
  <tr>
    <td>
      IET Computer Vision
    </td>
  </tr>  
  <tr>
    <td>
      IEEE Robotics and Automation Letters (RA-L)
    </td>
  </tr>  
  <tr>
    <td>
      IEEE Transactions on Image Processing (TIP)
    </td>
  </tr>  
</table>

(##) Volunteer

<table>
  <tr>
    <td>
      International Conference on Learning Representations (ICLR)
    </td>
    <td align="right">
      2021
    </td>
  </tr>  
  <tr>
    <td>
      International Conference on Machine Learning (ICML)
    </td>
    <td align="right">
      2021
    </td>
  </tr>  
</table>

(##) Mentor

<table>
  <tr>
    <td>
      SIGGRAPH Grad School Application Mentorship Program
    </td>
    <td align="right">
      2022
    </td>
  </tr>  
  <tr>
    <td>
      Toronto Graduate Application Assistance Program
    </td>
    <td align="right">
      2022, 2023
    </td>
  </tr>  
</table>

<link rel="stylesheet" href="cv.css">
<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js" charset="utf-8"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>