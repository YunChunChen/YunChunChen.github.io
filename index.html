<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <title>Yun-Chun Chen</title>
  <link rel="icon" type="image/png" href="img/yc.jpg"/>

  <!-- CSS  -->
  <link href="css/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/aos.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/font-awesome.min.css" rel="stylesheet" >
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>

</head>
<body>
  
  <div class="navbar-fixed">
    <nav class="">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light" href="#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#about">About</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="#publication">Publications</a></li>
        </ul>
      </div>
    </nav>
  </div>

<div id="home" class="parallax-container scrollspy">

  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="img/yc.jpg">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Yun-Chun Chen</h5>
        <hr>
        <br>
        <h6 class="profile-link"><a href="https://www.utoronto.ca">University of Toronto</a></h6 class="profile-link">
        <br>
        <h6 class="profile-link"><a href="https://vectorinstitute.ai">Vector Institute</a></h6 class="profile-link">
        <br>
        <h6 class="profile-link"><b>Email</b>: <a href="mailto:ycchen@cs.toronto.edu">ycchen@cs.toronto.edu</a></h6 class="profile-link">
        <br>
        <h6 class="profile-link">
        <a href="CV/CV.pdf" style="color:white;font-size:14pt">CV</a> &nbsp; | &nbsp;
        <a href="https://github.com/YunChunChen" style="color:white;font-size:14pt">GitHub</a> &nbsp; | &nbsp; 
        <a href="https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=AJsN-F7Bg9WggHd0xK7qIx-wii596FC5nocE0dDqLWgftb97mNlK91nsTp0O2_7esVZGVOTEgL_L_keUEd5TMoNIZflibtloLjp59VRXe7J6mvSoxzPdMzQ&user=TiCSofEAAAAJ" style="color:white;font-size:14pt">Google Scholar</a> &nbsp; | &nbsp;
        <a href="https://www.linkedin.com/in/ycchen918/" style="color:white;font-size:14pt">LinkedIn</a> &nbsp; | &nbsp; 
        <a href="https://twitter.com/ycchen918" style="color:white;font-size:14pt">Twitter</a>
        </h6>
    </div>
  </div>
  <div class="parallax"><img src="img/cover_blur.png" alt="Unsplashed background img 1"></div>
</div>


<div class="section about-section scrollspy" id="about">
  <div class="row container">
    <br>
    <div class="row">
      <div class="title">About me</div>
      <hr>
    </div>
    <div class="row">
        <p>I am a second-year Ph.D. student in <a href="https://web.cs.toronto.edu">Computer Science</a> at the <a href="https://www.utoronto.ca">University of Toronto</a>, advised by <a href="https://animesh.garg.tech">Animesh Garg</a>. I also work closely with <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>. I am affiliated with the <a href="https://vectorinstitute.ai">Vector Institute</a>, <a href="https://robotics.utoronto.ca/">UofT Robotics Institute</a> and <a href="https://datasciences.utoronto.ca/">UofT Data Sciences Institute</a>.</p>

        <p>My research interests are in the areas of computer vision and robotics. I am particularly interested in representation learning, geometric deep learning, and 3D vision.</p>
        
        <p>In 2021, I was an intern at <a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> on the <a href="https://www.nvidia.com/en-us/research/robotics/">Robotics</a> team, working with <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>, <a href="http://adithyamurali.com/">Adithya Murali</a>, and <a href="https://balakumar-s.github.io/">Balakumar Sundaralingam</a> on robotic grasping and motion planning.</p>

        <p>I received my Bachelor of Science degree in <a href="https://web.ee.ntu.edu.tw/eng/index.php">Electrical Engineering</a> from <a href="http://www.ntu.edu.tw/english/">National Taiwan University</a> in 2018. Previously, I was fortunate to work with <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a> at UC Merced, <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a> at Virginia Tech, and <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a> at Academia Sinica.</p>
    </div>
  </div>
</div>

<div class="section news-section scrollspy" id="news">
  <div class="row container">
    <br>
    <div class="row">
      <div class="title">News</div>
      <hr>
    </div>
    <div class="row">
      <ul>
      	<li>03 / 2022: &nbsp; I will be presenting our work at the <a href="https://toronto-geometry-colloquium.github.io/">Toronto Geometry Colloquium</a>.</li>
      	<li>03 / 2022: &nbsp; One paper on 3D geometric shape assembly is accepted to <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.</li>
      	<li>03 / 2022: &nbsp; I am serving as a reviewer for <a href="https://icml.cc/Conferences/2022">ICML 2022</a>, <a href="https://iclr.cc/Conferences/2022">ICLR 2022</a>, <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>, and <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.</li>
      	<li>01 / 2022: &nbsp; I am working as a teaching assistant for <a href="https://www.pair.toronto.edu/csc375-w22/">CSC 375: Algorithmic Intelligence in Robotics</a> and <a href="https://uoft-csc413.github.io/2022/">CSC 413/2516: Neural Networks and Deep Learning</a>. </li>
      	<li>10 / 2021: &nbsp; I am serving as a reviewer for <a href="https://www.ieee-ras.org/publications/ra-l">IEEE Robotics and Automation Letters (RA-L)</a>, <a href="https://www.journals.elsevier.com/image-and-vision-computing">Image and Vision Computing (IVC)</a>, and <a href="https://ietresearch.onlinelibrary.wiley.com/journal/17519640">IET Computer Vision</a>.</li>
      	<li>10 / 2021: &nbsp; I am serving as a program committee for <a href="https://ijcai-22.org/">IJCAI 2022</a>, <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a>, and <a href="http://wacv2022.thecvf.com/">WACV 2022</a>.</li>
      	<li>10 / 2021: &nbsp; One paper on <a href="https://arxiv.org/abs/2103.14182">3D Human Pose and Shape Estimation</a> is accepted to <a href="https://www.journals.elsevier.com/computer-vision-and-image-understanding">CVIU 2021</a>.</li>
      	<li>06 / 2021: &nbsp; One paper on <a href="https://arxiv.org/abs/2101.07241">visual imitation learning</a> is accepted to <a href="https://www.iros2021.org/">IROS 2021</a>.</li>
      	<li>06 / 2021: &nbsp; I am serving as a volunteer for <a href="https://iclr.cc/Conferences/2021">ICLR 2021</a> and <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</li>
        <li>05 / 2021: &nbsp; Start my internship at <a href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a> on the <a href="https://www.nvidia.com/en-us/research/robotics/">Robotics</a> team.</li>
        <li>05 / 2021: &nbsp; I am selected as the <a href="https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf">Top 25% of Program Committee Members</a> of <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</li>
        <li>04 / 2021: &nbsp; I am serving as a program committee for <a href="https://nips.cc/Conferences/2021">NeurIPS 2021</a>, <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>, <a href="http://wacv2021.thecvf.com/home">WACV 2021</a>, and <a href="https://www.grc.org/">Gordon Research Conference/Seminar in Robotics, 2022</a>.</li>
        <li>01 / 2021: &nbsp; I am serving as a reviewer for <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>, <a href="https://iclr.cc/Conferences/2021">ICLR 2021</a>, <a href="http://www.icra2021.org/">ICRA 2021</a>, and <a href="https://www.bmvc2021.com/">BMVC 2021</a>.</li>
        <li>01 / 2021: &nbsp; I am working as a teaching assistant for <a href="https://csc413-uoft.github.io/2021/">CSC 413/2516: Neural Networks and Deep Learning</a>. </li>
        <li>12 / 2020: &nbsp; I am serving as a reviewer for <a href="https://www.springer.com/journal/11263">International Journal of Computer Vision (IJCV)</a>. </li>
        <li>10 / 2020: &nbsp; I am serving as a senior program committee for <a href="https://ijcai-21.org/">IJCAI 2021</a>.</li>
        <li>09 / 2020: &nbsp; Start my Ph.D. at the <a href="https://www.utoronto.ca">University of Toronto</a> and the <a href="https://vectorinstitute.ai">Vector Institute</a>. </li>
        <li>09 / 2020: &nbsp; I am serving as a reviewer for <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing (TIP)</a>. </li>
        <li>08 / 2020: &nbsp; I am serving as a reviewer for <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>, <a href="https://eccv2020.eu/">ECCV 2020</a>, <a href="https://nips.cc/Conferences/2020">NeurIPS 2020</a>, <a href="https://www.robot-learning.org/">CoRL 2020</a>, <a href="https://www.bmvc2020-conference.com/">BMVC 2020</a>, and <a href="https://accv2020.github.io/">ACCV 2020</a>.</li>
        <li>07 / 2020: &nbsp; Two papers on <a href="https://arxiv.org/abs/2008.11713">neural architecture search</a> and <a href="https://arxiv.org/abs/2008.11203">meta-learning</a> are accepted to <a href="https://eccv2020.eu/">ECCV 2020</a>.</li>
        <li>03 / 2020: &nbsp; One paper on <a href="https://arxiv.org/abs/1906.05857">joint semantic matching and object co-segmentation</a> is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">PAMI 2021</a>.</li>
        <li>09 / 2019: &nbsp; I am serving as a program committee for <a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a>.</li>
        <li>07 / 2019: &nbsp; One paper on <a href="https://arxiv.org/abs/1908.06052">cross-resolution generative modeling</a> is accepted to <a href="https://iccv2019.thecvf.com/">ICCV 2019</a>.</li>
        <li>03 / 2019: &nbsp; I am serving as a reviewer for <a href="https://iccv2019.thecvf.com/">ICCV 2019</a>, <a href="https://bmvc2019.org/">BMVC 2019</a>, and <a href="https://www.2019.ieeeicip.org/2019.ieeeicip.org/index.html">ICIP 2019</a>.</li>
        <li>02 / 2019: &nbsp; One paper on <a href="https://arxiv.org/abs/2001.03182">unsupervised domain adaptation</a> is accepted to <a href="https://cvpr2019.thecvf.com/">CVPR 2019</a>.</li>
        <li>11 / 2018: &nbsp; One oral paper on <a href="https://arxiv.org/abs/1907.10843">representation learning</a> is accepted to <a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a>.</li>
        <li>10 / 2018: &nbsp; We won the <b>Third Place</b> in <a href="https://2018.ieeeicip.org/VIPCup.asp">IEEE Video and Image Processing (VIP) Cup</a>.</li>
        <li>07 / 2018: &nbsp; One paper on <a href="https://arxiv.org/abs/2004.00144">semantic matching</a> is accepted to <a href="">ACCV 2018</a>.</li>
      </ul>
    </div>
  </div>
</div>

<div class="section publication-section scrollspy" id="publication">
  <div class="row container">
    <br>
    <div class="row">
      <div class="title">Selected Publications</div>
      <hr>
    </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="https://lihd1003.github.io/">Haoda Li</a>,
            <a href="http://www.cs.toronto.edu/~dylanturpin/">Dylan Turpin</a>,
            <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>, and
            <a href="https://animesh.garg.tech/">Animesh Garg</a> <br />
          </div>
          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</div> 
          [<a href="" target="_blank">Paper</a>]
          [<a href="https://neural-shape-mating.github.io/" target="_blank">Project page</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/IROS-21/teaser.gif">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos</div>
          <div class="paper-author"> 
            <a href="https://haoyu-x.github.io/">Haoyu Xiong</a>,
            <a href="https://quanzhou-li.github.io/">Quanzhou Li</a>,
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="https://homangab.github.io/">Homanga Bharadhwaj</a>,
            <a href="https://www.samsinha.me/">Samarth Sinha</a>, and
            <a href="https://animesh.garg.tech/">Animesh Garg</a> <br />
          </div>
          <div class="paper-conf">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021</div> 
          <div class="paper-conf">RSS Workshop on Visual Learning and Reasoning for Robotics, 2021</div> 
          <div class="paper-conf">ICML Workshop on Human in the Loop Learning, 2021</div> 
          [<a href="https://arxiv.org/abs/2101.07241" target="_blank">Paper</a>]
          [<a href="http://www.pair.toronto.edu/lbw-kp/" target="_blank">Project page</a>]
          [<a href="https://youtu.be/Retu1q-BbEo" target="_blank">Video</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/PAMI-20/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Show, Match and Segment: Joint Weakly Supervised Learning of Semantic Matching and Object Co-segmentation</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a>,
            <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>, and
            <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a> <br />
          </div>
          <div class="paper-conf">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2021</div>
          [<a href="https://arxiv.org/abs/1906.05857" target="_blank">Paper</a>]
          [<a href="https://yunchunchen.github.io/MaCoSNet-web/" target="_blank">Project page</a>]
          [<a href="https://github.com/YunChunChen/MaCoSNet-pytorch">Code</a>]
          [<a href="papers/PAMI-20/slides.pdf">Slides</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/CVIU-21/teaser.gif">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Self-Attentive 3D Human Pose and Shape Estimation from Videos</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="https://mpicci.github.io/">Marco Piccirilli</a>,
            <a href="https://www.linkedin.com/in/rpiramuthu/">Robinson Piramuthu</a>, and
            <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
          </div>
          <div class="paper-conf">Computer Vision and Image Understanding (CVIU), 2021</div> 
          [<a href="https://arxiv.org/abs/2103.14182" target="_blank">Paper</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/ECCV-20/NAS-DIP/teaser.gif">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">NAS-DIP: Learning Deep Image Prior with Neural Architecture Search</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b><sup>*</sup>,
            <a href="https://gaochen315.github.io">Chen Gao</a><sup>*</sup>,
            <a href="http://estherrobb.com">Esther Robb</a>, and
            <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a> <br />
          </div>
          <div class="paper-conf">European Conference on Computer Vision (ECCV), 2020</div>
          [<a href="https://arxiv.org/abs/2008.11713" target="_blank">Paper</a>]
          [<a href="https://yunchunchen.github.io/NAS-DIP/" target="_blank">Project page</a>]
          [<a href="https://github.com/YunChunChen/NAS-DIP-pytorch" target="_blank">GitHub</a>]
          [<a href="https://colab.research.google.com/drive/1BhmZMeyGGP_T5SLPdLlkGUZLhrnO1FdF?usp=sharing" target="_blank">Colab</a>]
          [<a href="papers/ECCV-20/NAS-DIP/highlight.mp4" target="_blank">Highlight video</a>]
          [<a href="papers/ECCV-20/NAS-DIP/highlight.pdf" target="_blank">Highlight slides</a>]
          [<a href="papers/ECCV-20/NAS-DIP/full.mp4" target="_blank">Full video</a>]
          [<a href="papers/ECCV-20/NAS-DIP/full.pdf" target="_blank">Full slides</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/ECCV-20/Meta/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Learning to Learn in a Semi-Supervised Fashion</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="">Chao-Te Chou</a>, and
            Yu-Chiang Frank Wang <br />
          </div>
          <div class="paper-conf">European Conference on Computer Vision (ECCV), 2020</div>
          [<a href="https://arxiv.org/abs/2008.11203" target="_blank">Paper</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/arXiv-20/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Cross-Resolution Adversarial Dual Network for Person Re-Identification and Beyond</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b><sup>*</sup>,
            <a href="https://yujheli.github.io">Yu-Jhe Li</a><sup>*</sup>,
            <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a>, and
            Yu-Chiang Frank Wang <br />
          </div>
          <div class="paper-conf">arXiv preprint arXiv:2002.09274</div>
          [<a href="https://arxiv.org/abs/2002.09274" target="_blank">Paper</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/ICCV-19/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Recover and Identify: A Generative Dual Model for Cross-Resolution Person Re-Identification</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b><sup>*</sup>,
            <a href="https://yujheli.github.io">Yu-Jhe Li</a><sup>*</sup>,
            <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a>,
            Xiaofei Du, and
            Yu-Chiang Frank Wang <br />
          </div>
          <div class="paper-conf">IEEE International Conference on Computer Vision (ICCV), 2019</div>
          [<a href="https://arxiv.org/abs/1908.06052" target="_blank">Paper</a>]
          [<a href="papers/ICCV-19/slides.pptx">Slides</a>]
          [<a href="papers/ICCV-19/poster.pdf">Poster</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/CVPR-19/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">CrDoCo: Pixel-level Domain Transfer with Cross-Domain Consistency</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a>,
            <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>, and
            <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a> <br />
          </div>
          <div class="paper-conf">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019</div>
          [<a href="https://arxiv.org/abs/2001.03182">Paper</a>]
          [<a href="https://yunchunchen.github.io/CrDoCo/">Project Page</a>]
          [<a href="https://github.com/YunChunChen/CrDoCo-pytorch">Code</a>]
          [<a href="papers/CVPR-19/slides.pptx">Slides</a>]
          [<a href="papers/CVPR-19/poster.pdf">Poster</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/AAAI-19/teaser.png">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Learning Resolution-Invariant Deep Representations for Person Re-Identification</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b><sup>*</sup>,
            <a href="https://yujheli.github.io">Yu-Jhe Li</a><sup>*</sup>,
            Xiaofei Du, and
            Yu-Chiang Frank Wang <br />
          </div>
          <div class="paper-conf">AAAI Conference on Artificial Intelligence (AAAI), 2019</div>
          <font color="red">Oral Presentation</font> <br />
          [<a href="https://arxiv.org/abs/1907.10843">Paper</a>]
          [<a href="papers/AAAI-19/slides.pptx">Slides</a>]
          [<a href="papers/AAAI-19/poster.pdf">Poster</a>]
        </div>
      </div>

      <div class="row paper-block">
        <div class="col s12 m12 l4 center">
          <img class="responsive-img" src="papers/ACCV-18/teaser.jpg">
        </div>
        <div class="col s12 m12 l8">
          <div class="paper-title">Deep Semantic Matching with Foreground Detection and Cycle-Consistency</div>
          <div class="paper-author"> 
            <b><a href="https://yunchunchen.github.io">Yun-Chun Chen</a></b>,
            Po-Hsiang Huang,
            Li-Yu Yu,
            <a href="https://jbhuang0604.github.io/">Jia-Bin Huang</a>,
            <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>, and
            <a href="https://sites.google.com/site/yylinweb/">Yen-Yu Lin</a> <br />
          </div>
          <div class="paper-conf">Asian Conference on Computer Vision (ACCV), 2018</div>
          [<a href="https://arxiv.org/abs/2004.00144">Paper</a>]
          [<a href="https://yunchunchen.github.io/WeakMatchNet/">Project Page</a>]
          [<a href="https://github.com/YunChunChen/WeakMatchNet">Code</a>]
          [<a href="papers/ACCV-18/poster.pdf">Poster</a>]
        </div>
      </div>

  </div>
</div>

<footer class="page-footer white lighten-4">
    <div class="row">
      <div class="col l4 offset-l4 s12">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=THulLRlsDUvjodnYpDCviW_mAVbauRC9pS7yOCczJQI"></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Webpage template from <a href="http://www.wslai.net">Jason Lai</a>
    </div>
  
</footer>

<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="js/materialize.js"></script>
<script src="js/aos.js"></script>
<script src="js/init.js"></script>

</body>
</html>
